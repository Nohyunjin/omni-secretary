import asyncio
import json
from typing import Any, AsyncGenerator, Dict, List, Optional

from app.core.config import settings
from app.services.agent_service import process_user_input
from app.services.mcp_service import (
    cleanup_mcp_servers,
    initialize_mcp_servers,
    mcp_server_manager,
)
from fastapi import APIRouter, BackgroundTasks, Depends, HTTPException
from fastapi.responses import JSONResponse, StreamingResponse
from loguru import logger
from openai import AsyncOpenAI
from openai.types.chat import (
    ChatCompletionAssistantMessageParam,
    ChatCompletionMessageParam,
    ChatCompletionSystemMessageParam,
    ChatCompletionUserMessageParam,
)
from pydantic import BaseModel, Field

router = APIRouter()


class UserQuery(BaseModel):
    text: str
    api_key: Optional[str] = Field(None, description="OpenAI API í‚¤", exclude=True)
    stream: Optional[bool] = False
    model: Optional[str] = Field(
        None, description="ì‚¬ìš©í•  ëª¨ë¸ (ê¸°ë³¸ê°’: DEFAULT_MODEL)"
    )
    messageHistory: Optional[List[Dict[str, str]]] = Field(
        [], description="ì´ì „ ë©”ì‹œì§€ ê¸°ë¡ (ë©€í‹°í„´ ëŒ€í™”ë¥¼ ìœ„í•´ ì‚¬ìš©)"
    )

    class Config:
        # API í‚¤ê°€ ë¬¸ì„œì™€ ë¡œê·¸ì— ë…¸ì¶œë˜ì§€ ì•Šë„ë¡ ì„¤ì •
        schema_extra = {
            "example": {
                "text": "ë‚´ì¼ ì„œìš¸ ë‚ ì”¨ëŠ” ì–´ë•Œ?",
                "api_key": "sk-...",
                "stream": False,
                "model": "gpt-4",
                "messageHistory": [
                    {"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”"},
                    {
                        "role": "assistant",
                        "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
                    },
                ],
            }
        }


class MCPServerRequest(BaseModel):
    name: str
    config: Dict[str, Any]


async def generate_openai_stream(
    text: str,
    api_key: str,
    model: Optional[str] = None,
    message_history: Optional[List[Dict[str, str]]] = None,
) -> AsyncGenerator[str, None]:
    """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤. SSE í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        client = AsyncOpenAI(api_key=api_key)
        model_name = model or settings.DEFAULT_MODEL

        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì´ì „ ëŒ€í™” ê¸°ë¡ì„ í¬í•¨í•œ ë©”ì‹œì§€ ë°°ì—´ êµ¬ì„±
        messages: List[ChatCompletionMessageParam] = [
            ChatCompletionSystemMessageParam(
                role="system",
                content="ë‹¹ì‹ ì€ ìœ ìš©í•œ ë¹„ì„œ ì—­í• ì„ í•˜ëŠ” AIì…ë‹ˆë‹¤.",
            )
        ]

        # ì´ì „ ë©”ì‹œì§€ ê¸°ë¡ì´ ìˆìœ¼ë©´ ë³€í™˜í•˜ì—¬ ì¶”ê°€
        if message_history and len(message_history) > 0:
            for msg in message_history:
                if msg["role"] == "user":
                    messages.append(
                        ChatCompletionUserMessageParam(
                            role="user", content=msg["content"]
                        )
                    )
                elif msg["role"] == "assistant":
                    messages.append(
                        ChatCompletionAssistantMessageParam(
                            role="assistant", content=msg["content"]
                        )
                    )

        # í˜„ì¬ ì‚¬ìš©ì ì¿¼ë¦¬ ì¶”ê°€
        messages.append(ChatCompletionUserMessageParam(role="user", content=text))

        stream = await client.chat.completions.create(
            model=model_name,
            messages=messages,
            max_tokens=1000,
            stream=True,
        )

        async for chunk in stream:
            if chunk.choices and chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                # SSE í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ì „ì†¡, ensure_ascii=Falseë¡œ í•œê¸€ ì›ë³¸ ì „ì†¡
                event_data = json.dumps({"content": content}, ensure_ascii=False)
                yield f"data: {event_data}"

        # ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ì´ë²¤íŠ¸ ì „ì†¡
        yield f"data: {json.dumps({'content': '', 'finish_reason': 'stop'}, ensure_ascii=False)}"
    except Exception as e:
        error_msg = str(e)
        if api_key and api_key in error_msg:
            error_msg = error_msg.replace(api_key, "[API_KEY]")
        yield f"data: {json.dumps({'error': error_msg}, ensure_ascii=False)}"


async def generate_openai_stream_with_mcp(
    text: str,
    api_key: str,
    model: Optional[str] = None,
    message_history: Optional[List[Dict[str, str]]] = None,
) -> AsyncGenerator[str, None]:
    """OpenAI APIì™€ MCP ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤. SSE í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        client = AsyncOpenAI(api_key=api_key)
        model_name = model or settings.DEFAULT_MODEL

        # ë°˜ë³µ ì œì–´ ë³€ìˆ˜
        max_iterations = 10  # ìµœëŒ€ ë„êµ¬ í˜¸ì¶œ ë°˜ë³µ íšŸìˆ˜
        iteration = 0

        # MCP ì„œë²„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        all_tools = await mcp_server_manager.get_all_tools()
        available_tools = []

        # ëª¨ë“  MCP ì„œë²„ì˜ ë„êµ¬ë¥¼ ì¶”ê°€
        for server_name, tools in all_tools.items():
            logger.info(
                f"ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ: {server_name} ì„œë²„ì—ì„œ ë„êµ¬ {len(tools)}ê°œ ë°œê²¬"
            )
            for tool in tools:
                try:
                    # ë„êµ¬ ìŠ¤í‚¤ë§ˆ ë³€í™˜
                    schema = tool.get("inputSchema", {})
                    available_tools.append(
                        {
                            "type": "function",
                            "function": {
                                "name": tool.get("name"),
                                "description": tool.get("description", ""),
                                "parameters": schema,
                            },
                        }
                    )
                except Exception as e:
                    logger.error(f"ë„êµ¬ '{tool.get('name')}' ë³€í™˜ ì˜¤ë¥˜: {str(e)}")

        logger.info(f"ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ: ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ {len(available_tools)}ê°œ")

        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì´ì „ ëŒ€í™” ê¸°ë¡ì„ í¬í•¨í•œ ë©”ì‹œì§€ ë°°ì—´ êµ¬ì„±
        messages: List[ChatCompletionMessageParam] = [
            ChatCompletionSystemMessageParam(
                role="system",
                content="ë‹¹ì‹ ì€ ìœ ìš©í•œ ë¹„ì„œ ì—­í• ì„ í•˜ëŠ” AIì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì„ í•´ê²°í•˜ê¸° ìœ„í•´ ì ì ˆí•œ ë„êµ¬ë¥¼ í•„ìš”í•œ ë§Œí¼ ì‚¬ìš©í•˜ì„¸ìš”. ë³µì¡í•œ ì‘ì—…ì€ ì—¬ëŸ¬ ë„êµ¬ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„êµ¬ ì‚¬ìš©ì´ í•„ìš” ì—†ë‹¤ë©´ ë°”ë¡œ ì‘ë‹µí•˜ì„¸ìš”.",
            )
        ]

        # ì´ì „ ë©”ì‹œì§€ ê¸°ë¡ì´ ìˆìœ¼ë©´ ë³€í™˜í•˜ì—¬ ì¶”ê°€
        if message_history and len(message_history) > 0:
            logger.info(f"ì´ì „ ë©”ì‹œì§€ ê¸°ë¡ {len(message_history)}ê°œ ì¶”ê°€")
            for msg in message_history:
                if msg["role"] == "user":
                    messages.append(
                        ChatCompletionUserMessageParam(
                            role="user", content=msg["content"]
                        )
                    )
                elif msg["role"] == "assistant":
                    messages.append(
                        ChatCompletionAssistantMessageParam(
                            role="assistant", content=msg["content"]
                        )
                    )

        # í˜„ì¬ ì‚¬ìš©ì ì¿¼ë¦¬ ì¶”ê°€
        messages.append(ChatCompletionUserMessageParam(role="user", content=text))

        # ë„êµ¬ê°€ ì—†ëŠ” ê²½ìš° ì¼ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
        if not available_tools:
            logger.warning(
                "ì‚¬ìš© ê°€ëŠ¥í•œ MCP ë„êµ¬ê°€ ì—†ì–´ ì¼ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."
            )
            stream = await client.chat.completions.create(
                model=model_name,
                messages=messages,
                max_tokens=1000,
                stream=True,
            )

            async for chunk in stream:
                if chunk.choices and chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    event_data = json.dumps({"content": content}, ensure_ascii=False)
                    yield f"data: {event_data}"

            yield f"data: {json.dumps({'content': '', 'finish_reason': 'stop'}, ensure_ascii=False)}"
            return

        # AIê°€ ì‘ì—…ì„ ì™„ë£Œí•  ë•Œê¹Œì§€ ë„êµ¬ í˜¸ì¶œ ë£¨í”„ ì‹¤í–‰
        while iteration < max_iterations:
            # AIì—ê²Œ í˜„ì¬ ìƒíƒœë¥¼ ì „ë‹¬í•˜ê³  ë‹¤ìŒ í–‰ë™ ê²°ì • ìš”ì²­
            response = await client.chat.completions.create(
                model=model_name,
                messages=messages,  # type: ignore
                tools=available_tools,
                tool_choice="auto",
                max_tokens=1000,
            )

            # ë„êµ¬ í˜¸ì¶œì´ ì—†ìœ¼ë©´ ìµœì¢… ì‘ë‹µìœ¼ë¡œ ê°„ì£¼í•˜ê³  ìŠ¤íŠ¸ë¦¬ë°
            if not response.choices[0].message.tool_calls:
                # ìµœì¢… ì‘ë‹µ ë‚´ìš© ìŠ¤íŠ¸ë¦¬ë°
                assistant_message = response.choices[0].message.content or ""

                # ì²« ë²ˆì§¸ ë°˜ë³µì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ êµ¬ë¶„ì„  í‘œì‹œ
                if iteration > 0:
                    yield f"data: {json.dumps({'content': 'ìµœì¢… ì‘ë‹µ:'}, ensure_ascii=False)}"

                # ì‘ë‹µì„ ì‘ì€ ì²­í¬ë¡œ ë‚˜ëˆ ì„œ ìŠ¤íŠ¸ë¦¬ë°
                chunk_size = 20
                for i in range(0, len(assistant_message), chunk_size):
                    chunk = assistant_message[i : i + chunk_size]
                    event_data = json.dumps({"content": chunk}, ensure_ascii=False)
                    yield f"data: {event_data}"
                    await asyncio.sleep(0.01)  # ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼ë¥¼ ìœ„í•œ ì‘ì€ ì§€ì—°

                yield f"data: {json.dumps({'content': '', 'finish_reason': 'stop'}, ensure_ascii=False)}"
                return

            # ë„êµ¬ í˜¸ì¶œì´ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
            assistant_message = response.choices[0].message
            assistant_dict = {
                "role": "assistant",
                "content": assistant_message.content or "",
            }

            # tool_calls ì •ë³´ ì¶”ê°€
            if assistant_message.tool_calls:
                assistant_dict["tool_calls"] = [
                    {
                        "id": tool_call.id,
                        "type": "function",
                        "function": {
                            "name": tool_call.function.name,
                            "arguments": tool_call.function.arguments,
                        },
                    }
                    for tool_call in assistant_message.tool_calls
                ]

            messages.append(assistant_dict)  # type: ignore

            # ì²« ë°˜ë³µì´ê±°ë‚˜ ì´ì „ ë°˜ë³µì—ì„œë„ ë„êµ¬ë¥¼ ì‚¬ìš©í•œ ê²½ìš°ì˜ ë©”ì‹œì§€ í‘œì‹œ
            if iteration == 0:
                yield f"data: {json.dumps({'content': 'ğŸ” ìš”ì²­ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ë„êµ¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤...'}, ensure_ascii=False)}"
            else:
                yield f"data: {json.dumps({'content': f'ğŸ”„ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•˜ì—¬ ë„êµ¬ë¥¼ ë‹¤ì‹œ ì‚¬ìš©í•©ë‹ˆë‹¤({iteration+1}/{max_iterations})...'}, ensure_ascii=False)}"

            # ê° ë„êµ¬ í˜¸ì¶œì— ëŒ€í•´ ì²˜ë¦¬
            for tool_call in assistant_message.tool_calls:
                function_name = tool_call.function.name
                function_args = tool_call.function.arguments

                # JSON ë¬¸ìì—´ì„ íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                try:
                    args_dict = json.loads(function_args)
                except json.JSONDecodeError:
                    args_dict = {}

                # ì‚¬ìš©ìì—ê²Œ ë„êµ¬ í˜¸ì¶œ ì •ë³´ í‘œì‹œ
                yield f"data: {json.dumps({'content': f'ğŸ§° ë„êµ¬ ì‚¬ìš©: {function_name}'}, ensure_ascii=False)}"
                logger.info(f"ë„êµ¬ {function_name} í˜¸ì¶œ (ì¸ì: {args_dict})")

                # ë„êµ¬ ì‹¤í–‰
                result = None

                # ê¸°ë³¸ ì—ì½” ë„êµ¬ëŠ” ì§ì ‘ ì²˜ë¦¬
                if function_name == "echo":
                    result = args_dict.get("text", "")
                else:
                    # MCP ì„œë²„ì—ì„œ ë„êµ¬ ì°¾ê¸°
                    server_name, tool_info = mcp_server_manager.find_tool(function_name)

                    if server_name:
                        # MCP ì„œë²„ë¥¼ í†µí•´ ë„êµ¬ ì‹¤í–‰
                        try:
                            success, result = await mcp_server_manager.execute_tool(
                                server_name, function_name, args_dict
                            )
                            if not success:
                                logger.warning(
                                    f"ë„êµ¬ '{function_name}' ì‹¤í–‰ ì‹¤íŒ¨: {result}"
                                )
                                yield f"data: {json.dumps({'content': f'âš ï¸ ë„êµ¬ ì‹¤í–‰ ì‹¤íŒ¨: {result}'}, ensure_ascii=False)}"
                        except Exception as e:
                            logger.error(f"ë„êµ¬ '{function_name}' ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
                            result = f"ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}"
                            yield f"data: {json.dumps({'content': f'âš ï¸ ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}'}, ensure_ascii=False)}"
                    else:
                        result = f"ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë„êµ¬: {function_name}"
                        yield f"data: {json.dumps({'content': f'âš ï¸ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë„êµ¬: {function_name}'}, ensure_ascii=False)}"

                # ê²°ê³¼ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€
                messages.append(
                    {
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "name": function_name,
                        "content": str(result),
                    }
                )  # type: ignore

                # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ìš”ì•½ì„ ì‚¬ìš©ìì—ê²Œ í‘œì‹œ (ë„ˆë¬´ ê¸¸ë©´ ì¶•ì•½)
                result_str = str(result)
                if len(result_str) > 100:
                    short_result = result_str[:100] + "... (ê²°ê³¼ ì¶•ì•½ë¨)"
                    yield f"data: {json.dumps({'content': f'ğŸ“‹ ê²°ê³¼: {short_result}'}, ensure_ascii=False)}"
                else:
                    yield f"data: {json.dumps({'content': f'ğŸ“‹ ê²°ê³¼: {result_str}'}, ensure_ascii=False)}"

            # ë‹¤ìŒ ë°˜ë³µìœ¼ë¡œ
            iteration += 1

        # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ì‹œ
        if iteration >= max_iterations:
            yield f"data: {json.dumps({'content': f'âš ï¸ ìµœëŒ€ ë„êµ¬ í˜¸ì¶œ íšŸìˆ˜({max_iterations}íšŒ)ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ìµœì¢… ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.'}, ensure_ascii=False)}"

            # ìµœì¢… ì‘ë‹µ ìƒì„±
            final_response = await client.chat.completions.create(
                model=model_name,
                messages=messages,  # type: ignore
                max_tokens=1000,
            )

            final_answer = (
                final_response.choices[0].message.content
                or "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
            yield f"data: {json.dumps({'content': f'{final_answer}'}, ensure_ascii=False)}"
            yield f"data: {json.dumps({'content': '', 'finish_reason': 'stop'}, ensure_ascii=False)}"

    except Exception as e:
        error_msg = str(e)
        if api_key and api_key in error_msg:
            error_msg = error_msg.replace(api_key, "[API_KEY]")
        logger.error(f"ìŠ¤íŠ¸ë¦¬ë° MCP ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {error_msg}")
        yield f"data: {json.dumps({'error': error_msg}, ensure_ascii=False)}"


@router.post("/query")
async def query_agent(query: UserQuery):
    """
    ì—ì´ì „íŠ¸ì— ì¿¼ë¦¬ë¥¼ ë³´ë‚´ê³  ì‘ë‹µì„ ë°›ëŠ” ì—”ë“œí¬ì¸íŠ¸.

    stream=Trueì¼ ê²½ìš°ì—ë„ MCP ë„êµ¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    try:
        if not query.api_key:
            raise HTTPException(status_code=400, detail="OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤")

        # ìŠ¤íŠ¸ë¦¼ ëª¨ë“œì™€ ê´€ê³„ì—†ì´ process_user_inputì„ ì‚¬ìš©í•´ ì‘ë‹µ ìƒì„±
        # (ë‚´ë¶€ì ìœ¼ë¡œ MCP ë„êµ¬ í™œìš©)
        response = await process_user_input(
            query.text, query.api_key, query.model, message_history=query.messageHistory
        )

        # ì‘ë‹µ í˜•ì‹ë§Œ ìŠ¤íŠ¸ë¦¼ ì—¬ë¶€ì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì²˜ë¦¬
        if query.stream:
            # ìƒì„±ëœ ì „ì²´ ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë° í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
            async def stream_response():
                # ì‘ë‹µì„ ì ì ˆí•œ í¬ê¸°ë¡œ ë‚˜ëˆ„ì–´ ìŠ¤íŠ¸ë¦¬ë° (ì˜ˆ: 10ìì”©)
                chunk_size = 10
                for i in range(0, len(response), chunk_size):
                    chunk = response[i : i + chunk_size]
                    event_data = json.dumps({"content": chunk}, ensure_ascii=False)
                    yield f"data: {event_data}"
                    # ì‹¤ì œ ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼ë¥¼ ìœ„í•œ ì‘ì€ ì§€ì—°
                    await asyncio.sleep(0.05)

                # ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ì´ë²¤íŠ¸ ì „ì†¡
                yield f"data: {json.dumps({'content': '', 'finish_reason': 'stop'}, ensure_ascii=False)}"

            return StreamingResponse(
                stream_response(),
                media_type="text/event-stream",
            )
        else:
            # ì¼ë°˜ JSON ì‘ë‹µ
            logger.info(f"ì—ì´ì „íŠ¸ ì‘ë‹µ: {response[:100]}...")
            return JSONResponse({"response": response})

    except Exception as e:
        # ì˜¤ë¥˜ ë©”ì‹œì§€ì— API í‚¤ê°€ í¬í•¨ë˜ì§€ ì•Šë„ë¡ ì£¼ì˜
        error_msg = str(e)
        if query.api_key and query.api_key in error_msg:
            error_msg = error_msg.replace(query.api_key, "[API_KEY]")
        raise HTTPException(status_code=500, detail=error_msg)


@router.get("/mcp/servers")
async def get_mcp_servers():
    """MCP ì„œë²„ ëª©ë¡ ì¡°íšŒ"""
    try:
        status = await mcp_server_manager.get_all_server_status()
        return JSONResponse(
            {
                "servers": status,
                "config": settings.MCP_SERVERS,
            }
        )
    except Exception as e:
        logger.error(f"MCP ì„œë²„ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/mcp/servers/{server_name}/start")
async def start_mcp_server(server_name: str, background_tasks: BackgroundTasks):
    """MCP ì„œë²„ ì‹œì‘"""
    if server_name not in settings.MCP_SERVERS:
        raise HTTPException(
            status_code=404, detail=f"ì„œë²„ '{server_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        )

    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì„œë²„ ì‹œì‘
    background_tasks.add_task(mcp_server_manager.start_server, server_name)
    return JSONResponse({"message": f"ì„œë²„ '{server_name}' ì‹œì‘ ì¤‘"})


@router.post("/mcp/servers/{server_name}/stop")
async def stop_mcp_server(server_name: str):
    """MCP ì„œë²„ ì¤‘ì§€"""
    if server_name not in settings.MCP_SERVERS:
        raise HTTPException(
            status_code=404, detail=f"ì„œë²„ '{server_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        )

    result = await mcp_server_manager.stop_server(server_name)
    if result:
        return JSONResponse({"message": f"ì„œë²„ '{server_name}' ì¤‘ì§€ë¨"})
    else:
        raise HTTPException(status_code=500, detail=f"ì„œë²„ '{server_name}' ì¤‘ì§€ ì‹¤íŒ¨")


@router.get("/mcp/servers/{server_name}/tools")
async def get_mcp_server_tools(server_name: str):
    """MCP ì„œë²„ì˜ ë„êµ¬ ëª©ë¡ ì¡°íšŒ"""
    if server_name not in settings.MCP_SERVERS:
        raise HTTPException(
            status_code=404, detail=f"ì„œë²„ '{server_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        )

    if server_name not in mcp_server_manager.servers:
        raise HTTPException(
            status_code=400, detail=f"ì„œë²„ '{server_name}'ê°€ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤"
        )

    tools = mcp_server_manager.servers[server_name].get("tools", [])
    return JSONResponse({"tools": tools})


@router.post("/mcp/servers")
async def add_mcp_server(server: MCPServerRequest):
    """MCP ì„œë²„ ì¶”ê°€"""
    if server.name in settings.MCP_SERVERS:
        raise HTTPException(
            status_code=400, detail=f"ì„œë²„ '{server.name}'ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤"
        )

    # ì„¤ì •ì— ì„œë²„ ì¶”ê°€
    settings.MCP_SERVERS[server.name] = server.config
    settings.save_config()

    return JSONResponse(
        {"message": f"ì„œë²„ '{server.name}' ì¶”ê°€ë¨", "server": server.config}
    )


@router.put("/mcp/servers/{server_name}")
async def update_mcp_server(server_name: str, server: Dict[str, Any]):
    """MCP ì„œë²„ ì„¤ì • ì—…ë°ì´íŠ¸"""
    if server_name not in settings.MCP_SERVERS:
        raise HTTPException(
            status_code=404, detail=f"ì„œë²„ '{server_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        )

    # ì‹¤í–‰ ì¤‘ì¸ ì„œë²„ ì¤‘ì§€
    if server_name in mcp_server_manager.servers:
        await mcp_server_manager.stop_server(server_name)

    # ì„¤ì • ì—…ë°ì´íŠ¸
    settings.MCP_SERVERS[server_name] = server
    settings.save_config()

    return JSONResponse(
        {"message": f"ì„œë²„ '{server_name}' ì—…ë°ì´íŠ¸ë¨", "server": server}
    )


@router.delete("/mcp/servers/{server_name}")
async def delete_mcp_server(server_name: str):
    """MCP ì„œë²„ ì‚­ì œ"""
    if server_name not in settings.MCP_SERVERS:
        raise HTTPException(
            status_code=404, detail=f"ì„œë²„ '{server_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        )

    # ì‹¤í–‰ ì¤‘ì¸ ì„œë²„ ì¤‘ì§€
    if server_name in mcp_server_manager.servers:
        await mcp_server_manager.stop_server(server_name)

    # ì„¤ì •ì—ì„œ ì„œë²„ ì‚­ì œ
    del settings.MCP_SERVERS[server_name]
    settings.save_config()

    return JSONResponse({"message": f"ì„œë²„ '{server_name}' ì‚­ì œë¨"})


@router.get("/mcp-tools", response_model=Dict[str, Any], tags=["agent"])
async def get_mcp_tools() -> Dict[str, Any]:
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ MCP ë„êµ¬ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        # ëª¨ë“  ì„œë²„ ìƒíƒœ ì¡°íšŒ
        servers_status = await mcp_server_manager.get_all_server_status()

        # ëª¨ë“  MCP ì„œë²„ì˜ ë„êµ¬ ëª©ë¡ ì¡°íšŒ
        all_tools = await mcp_server_manager.get_all_tools()

        # ê° ì„œë²„ì˜ ìƒíƒœì™€ ë„êµ¬ ëª©ë¡ì„ í•©ì¹¨
        result = {
            "servers": servers_status,
            "tools": all_tools,
            "total_tools_count": sum(len(tools) for tools in all_tools.values()),
        }

        return result
    except Exception as e:
        logger.error(f"MCP ë„êµ¬ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(
            status_code=500, detail=f"MCP ë„êµ¬ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        )


@router.post("/stream")
async def stream_agent(query: UserQuery):
    """
    ì—ì´ì „íŠ¸ì— ì¿¼ë¦¬ë¥¼ ë³´ë‚´ê³  ìŠ¤íŠ¸ë¦¬ë° í˜•ì‹ìœ¼ë¡œ ì‘ë‹µì„ ë°›ëŠ” ì—”ë“œí¬ì¸íŠ¸.
    MCP ë„êµ¬ê°€ í†µí•©ëœ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ì§ì ‘ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        if not query.api_key:
            raise HTTPException(status_code=400, detail="OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤")

        # ì§ì ‘ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± (MCP ë„êµ¬ í™œìš©)
        return StreamingResponse(
            generate_openai_stream_with_mcp(
                query.text,
                query.api_key,
                query.model,
                message_history=query.messageHistory,
            ),
            media_type="text/event-stream",
        )

    except Exception as e:
        # ì˜¤ë¥˜ ë©”ì‹œì§€ì— API í‚¤ê°€ í¬í•¨ë˜ì§€ ì•Šë„ë¡ ì£¼ì˜
        error_msg = str(e)
        if query.api_key and query.api_key in error_msg:
            error_msg = error_msg.replace(query.api_key, "[API_KEY]")
        raise HTTPException(status_code=500, detail=error_msg)
